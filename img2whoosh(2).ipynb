{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI-zc8F_RSNS"
      },
      "outputs": [],
      "source": [
        "# open in collab\n",
        "# https://colab.research.google.com/drive/1LCKjJ_MGG31_6lB50FCR3qHplwy7pfqU#scrollTo=oI-zc8F_RSNS\n",
        "\n",
        "!pip install flask flask-cors pyngrok diffusers transformers torch torchvision\n",
        "\n",
        "# Add your ngrok token (my token is given for now dont know if it is permanent)\n",
        "!ngrok authtoken 2vMFWNjkoNb4wcQHx2OihBG3kjJ_4HLt2TBTwsnsAqpFPNfT2 # doesnt work without this\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")  ##dont know if this is permanent also (without this shows warning )\n"
      ],
      "metadata": {
        "id": "b-Ut87wnVefV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, send_file\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "from PIL import Image\n",
        "import io\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load models\n",
        "text2img_pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\").to(device)\n",
        "img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\").to(device)\n",
        "caption_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "caption_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "@app.route(\"/process\", methods=[\"POST\"])\n",
        "def process():\n",
        "    data = request.form  ## maybe we just have to put the values over here\n",
        "    prompt = data.get(\"text\", \"\").strip()\n",
        "    height = int(data.get(\"height\", 512))\n",
        "    width = int(data.get(\"width\", 512))\n",
        "    image_file = request.files.get(\"image\")\n",
        "\n",
        "    mode = \"\"\n",
        "    if image_file and not prompt:\n",
        "        mode = \"caption\"\n",
        "    elif prompt and not image_file:\n",
        "        mode = \"text2img\"\n",
        "    elif prompt and image_file:\n",
        "        mode = \"img2img\"\n",
        "\n",
        "    if mode == \"caption\":\n",
        "        image = Image.open(image_file).convert(\"RGB\")\n",
        "        inputs = caption_processor(image, return_tensors=\"pt\").to(device)\n",
        "        output = caption_model.generate(**inputs)\n",
        "        caption = caption_processor.decode(output[0], skip_special_tokens=True)\n",
        "        return jsonify({\"mode\": mode, \"caption\": caption})\n",
        "\n",
        "    elif mode == \"text2img\":\n",
        "        image = text2img_pipe(prompt, height=height, width=width).images[0]\n",
        "        image_path = \"output.png\"\n",
        "        image.save(image_path)\n",
        "        return send_file(image_path, mimetype=\"image/png\")\n",
        "\n",
        "    elif mode == \"img2img\":\n",
        "        init_image = Image.open(image_file).convert(\"RGB\").resize((width, height))\n",
        "        image = img2img_pipe(prompt=prompt, image=init_image, strength=0.6).images[0]\n",
        "        image_path = \"output.png\"\n",
        "        image.save(image_path)\n",
        "        return send_file(image_path, mimetype=\"image/png\")\n",
        "\n",
        "    return jsonify({\"error\": \"Invalid input\"}), 400\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(\"Backend running at:\", public_url)\n",
        "\n",
        "import threading\n",
        "\n",
        "def run_flask():\n",
        "    app.run(port=5000)\n",
        "\n",
        "# thread given because it shows it is running the same cell and cannot proceede to the next one. Thread enables to run this cell completely then go to cell 4\n",
        "\n",
        "thread = threading.Thread(target=run_flask)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "YU0_TA6BSyFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "public_url=\"https://d5aa-104-198-5-105.ngrok-free.app\"\n",
        "applied_url = public_url + '/process'\n",
        "print(applied_url)"
      ],
      "metadata": {
        "id": "6WcG0FvQi1UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after printing the applied url just put it inside [https:// ...](put here) --output result.png\n",
        "!curl -X POST -F \"text=A cute fox in space\" https://d5aa-104-198-5-105.ngrok-free.app/process --output result.png\n",
        "from IPython.display import Image as IPImage\n",
        "IPImage(\"result.png\")\n"
      ],
      "metadata": {
        "id": "wchH5LrFc78o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_4yb1Iaqfrfu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}